{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c99f9b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b07297",
   "metadata": {},
   "source": [
    "## Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bed5705d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1956967341</td>\n",
       "      <td>empty</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956967696</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956967789</td>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1956968416</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweet_id   sentiment                                            content\n",
       "0  1956967341       empty  @tiffanylue i know  i was listenin to bad habi...\n",
       "1  1956967666     sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
       "2  1956967696     sadness                Funeral ceremony...gloomy friday...\n",
       "3  1956967789  enthusiasm               wants to hang out with friends SOON!\n",
       "4  1956968416     neutral  @dannycastillo We want to trade with someone w..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_URL = \"https://raw.githubusercontent.com/entbappy/Branching-tutorial/refs/heads/master/tweet_emotions.csv\"\n",
    "\n",
    "df = pd.read_csv(DATA_URL)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b841b951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>empty</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@JohnLloydTaylor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>love</td>\n",
       "      <td>Happy Mothers Day  All my love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>love</td>\n",
       "      <td>Happy Mother's Day to all the mommies out ther...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>happiness</td>\n",
       "      <td>@niariley WASSUP BEAUTIFUL!!! FOLLOW ME!!  PEE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>love</td>\n",
       "      <td>@mopedronin bullet train from tokyo    the gf ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentiment                                            content\n",
       "0           empty  @tiffanylue i know  i was listenin to bad habi...\n",
       "1         sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
       "2         sadness                Funeral ceremony...gloomy friday...\n",
       "3      enthusiasm               wants to hang out with friends SOON!\n",
       "4         neutral  @dannycastillo We want to trade with someone w...\n",
       "...           ...                                                ...\n",
       "39995     neutral                                   @JohnLloydTaylor\n",
       "39996        love                     Happy Mothers Day  All my love\n",
       "39997        love  Happy Mother's Day to all the mommies out ther...\n",
       "39998   happiness  @niariley WASSUP BEAUTIFUL!!! FOLLOW ME!!  PEE...\n",
       "39999        love  @mopedronin bullet train from tokyo    the gf ...\n",
       "\n",
       "[40000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delete tweet id\n",
    "df.drop(columns=['tweet_id'], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dbc4d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select sentiment categories\n",
    "label_categories = ['happiness', 'sadness']\n",
    "final_df = df[df['sentiment'].isin(label_categories)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d3ba23c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27061</th>\n",
       "      <td>happiness</td>\n",
       "      <td>@djnvs LoL! there u go..that's the spirit haha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7055</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Regrettin some of the decisions I made</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21502</th>\n",
       "      <td>happiness</td>\n",
       "      <td>THE best job in the world &amp;amp; yes its in Aus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130</th>\n",
       "      <td>sadness</td>\n",
       "      <td>@OpheliaPunk i wish i wasn't all  bummed but i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33767</th>\n",
       "      <td>happiness</td>\n",
       "      <td>@tabithalynnne lmao, yep</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment                                            content\n",
       "27061  happiness     @djnvs LoL! there u go..that's the spirit haha\n",
       "7055     sadness             Regrettin some of the decisions I made\n",
       "21502  happiness  THE best job in the world &amp; yes its in Aus...\n",
       "2130     sadness  @OpheliaPunk i wish i wasn't all  bummed but i...\n",
       "33767  happiness                           @tabithalynnne lmao, yep"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb5464de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\XPS\\AppData\\Local\\Temp\\ipykernel_11768\\3737934124.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  final_df['sentiment'].replace({'happiness': 1, 'sadness': 0}, inplace=True)\n",
      "C:\\Users\\XPS\\AppData\\Local\\Temp\\ipykernel_11768\\3737934124.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  final_df['sentiment'].replace({'happiness': 1, 'sadness': 0}, inplace=True)\n",
      "C:\\Users\\XPS\\AppData\\Local\\Temp\\ipykernel_11768\\3737934124.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df['sentiment'].replace({'happiness': 1, 'sadness': 0}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# encode sentiment labels\n",
    "final_df['sentiment'].replace({'happiness': 1, 'sadness': 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64bc988f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>I should be sleep, but im not! thinking about ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>@charviray Charlene my love. I miss you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>@kelcouch I'm sorry  at least it's Friday?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            content\n",
       "1          0  Layin n bed with a headache  ughhhh...waitin o...\n",
       "2          0                Funeral ceremony...gloomy friday...\n",
       "6          0  I should be sleep, but im not! thinking about ...\n",
       "8          0            @charviray Charlene my love. I miss you\n",
       "9          0         @kelcouch I'm sorry  at least it's Friday?"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe0f93e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(final_df, test_size=0.2, random_state=42)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5ac0f8",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21666280",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /nltk_data/...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /nltk_data/...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /nltk_data/...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /nltk_data/...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords', download_dir='/nltk_data/')\n",
    "nltk.download('wordnet', download_dir='/nltk_data/')\n",
    "nltk.download(\"punkt\", download_dir='/nltk_data/')\n",
    "nltk.download('punkt_tab', download_dir='/nltk_data/')\n",
    "\n",
    "def lemmatization(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [token for token in tokens if token.lower() not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "\n",
    "def remove_numbers(text):\n",
    "    return re.sub(r'\\d+', '', text)\n",
    "\n",
    "\n",
    "def lowercase_text(text):\n",
    "    ## Convert text to lowercase\n",
    "    return text.lower()\n",
    "\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    ## Remove punctuation\n",
    "    return text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "\n",
    "def remove_urls(text):\n",
    "    ## Remove URLs\n",
    "    return re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "\n",
    "def remove_small_sentences(df, min_length=3):\n",
    "    ## Remove sentences shorter than min_length\n",
    "    df['content'] = df['content'].apply(lambda x: ''.join(x.split()) if len(x.split()) >= min_length else '')\n",
    "    \n",
    "    return df[df['content'].str.strip().astype(bool)]  # Remove empty rows\n",
    "\n",
    "def normalize_text(df):\n",
    "    ## Normalize contents of the DataFrame\n",
    "    df['content'] = df['content'].apply(lowercase_text)\n",
    "    df['content'] = df['content'].apply(remove_numbers)\n",
    "    df['content'] = df['content'].apply(remove_punctuation)\n",
    "    df['content'] = df['content'].apply(remove_urls)\n",
    "    df['content'] = df['content'].apply(remove_stop_words)\n",
    "    df['content'] = df['content'].apply(lemmatization)\n",
    "    return df\n",
    "\n",
    "def normalize_sentence(sentence):\n",
    "    ## Normalize a single sentence\n",
    "    sentence = lowercase_text(sentence)\n",
    "    sentence = remove_numbers(sentence)\n",
    "    sentence = remove_punctuation(sentence)\n",
    "    sentence = remove_urls(sentence)\n",
    "    sentence = remove_stop_words(sentence)\n",
    "    sentence = lemmatization(sentence)\n",
    "    return sentence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc0ae0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am number  in the world! # ? Let's celebrate  with joy and happiness! :) % guaranteed success.\n",
      "I am number  in the world! # ? Let's celebrate  with joy and happiness! :) % guaranteed success.\n",
      "I am number 1 in the world 1  Lets celebrate 2023 with joy and happiness  100 guaranteed success\n",
      "number world let celebrate joy happiness guaranteed success\n"
     ]
    }
   ],
   "source": [
    "test_string = \"I am number 1 in the world! #1 ? Let's celebrate 2023 with joy and happiness! :) 100% guaranteed success.\"\n",
    "cleaned_string = remove_numbers(test_string)\n",
    "print(cleaned_string)\n",
    "\n",
    "cleaned_string = ''.join([i for i in test_string if not i.isdigit()])\n",
    "print(cleaned_string)\n",
    "\n",
    "test_string = test_string.translate(str.maketrans('', '', string.punctuation))\n",
    "print(test_string)\n",
    "\n",
    "norm_string = normalize_sentence(test_string)\n",
    "print(norm_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc3bac8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = normalize_text(train_data)\n",
    "test_data = normalize_text(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c01c556c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'many farewell party sad see people leaving'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"content\"].iloc[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62d0d078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23531</th>\n",
       "      <td>0</td>\n",
       "      <td>quotmy problem isnt miss cause dontquot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8051</th>\n",
       "      <td>0</td>\n",
       "      <td>thats done already one proof there nothing fai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11499</th>\n",
       "      <td>0</td>\n",
       "      <td>hungry food steal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31288</th>\n",
       "      <td>1</td>\n",
       "      <td>foot hurtfinally bedwill forget crunch overver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18561</th>\n",
       "      <td>0</td>\n",
       "      <td>really ill atm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21697</th>\n",
       "      <td>1</td>\n",
       "      <td>chocolatesuze yes yes especially wine mushroom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19445</th>\n",
       "      <td>0</td>\n",
       "      <td>kickzfadayz boy better get tonight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20216</th>\n",
       "      <td>1</td>\n",
       "      <td>tafe actually quite good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>0</td>\n",
       "      <td>minute boarding hour home window seat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27810</th>\n",
       "      <td>0</td>\n",
       "      <td>intel gfx driver situation much better recent ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8299 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment                                            content\n",
       "23531          0            quotmy problem isnt miss cause dontquot\n",
       "8051           0  thats done already one proof there nothing fai...\n",
       "11499          0                                  hungry food steal\n",
       "31288          1  foot hurtfinally bedwill forget crunch overver...\n",
       "18561          0                                     really ill atm\n",
       "...          ...                                                ...\n",
       "21697          1  chocolatesuze yes yes especially wine mushroom...\n",
       "19445          0                 kickzfadayz boy better get tonight\n",
       "20216          1                           tafe actually quite good\n",
       "3258           0              minute boarding hour home window seat\n",
       "27810          0  intel gfx driver situation much better recent ...\n",
       "\n",
       "[8299 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c2bf0f",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2af8ad58",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_data['content'].values\n",
    "y_train = train_data['sentiment'].values\n",
    "\n",
    "x_test = test_data['content'].values\n",
    "y_test = test_data['sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6cd8a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Bag of words (CountVectorizer)\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit the vectorizer on the training data and transform both train and test data\n",
    "X_train_bow = vectorizer.fit_transform(x_train)\n",
    "X_test_bow = vectorizer.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "655268a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>14937</th>\n",
       "      <th>14938</th>\n",
       "      <th>14939</th>\n",
       "      <th>14940</th>\n",
       "      <th>14941</th>\n",
       "      <th>14942</th>\n",
       "      <th>14943</th>\n",
       "      <th>14944</th>\n",
       "      <th>14945</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 14947 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4  5  6  7  8  9  ...  14937  14938  14939  14940  14941  \\\n",
       "0  0  0  0  0  0  0  0  0  0  0  ...      0      0      0      0      0   \n",
       "1  0  0  0  0  0  0  0  0  0  0  ...      0      0      0      0      0   \n",
       "2  0  0  0  0  0  0  0  0  0  0  ...      0      0      0      0      0   \n",
       "3  0  0  0  0  0  0  0  0  0  0  ...      0      0      0      0      0   \n",
       "4  0  0  0  0  0  0  0  0  0  0  ...      0      0      0      0      0   \n",
       "\n",
       "   14942  14943  14944  14945  label  \n",
       "0      0      0      0      0      0  \n",
       "1      0      0      0      0      0  \n",
       "2      0      0      0      0      0  \n",
       "3      0      0      0      0      1  \n",
       "4      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 14947 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.DataFrame(X_train_bow.toarray())\n",
    "#train_df.columns = vectorizer.get_feature_names_out()\n",
    "\n",
    "train_df[\"label\"] = y_train\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcd4e24",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a05b3dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\XPS\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [22:36:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7730120481927711\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     sadness       0.81      0.72      0.76      1060\n",
      "   happiness       0.74      0.83      0.78      1015\n",
      "\n",
      "    accuracy                           0.77      2075\n",
      "   macro avg       0.78      0.77      0.77      2075\n",
      "weighted avg       0.78      0.77      0.77      2075\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define and train the model XGBoost model\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "\n",
    "xgb_model.fit(X_train_bow, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = xgb_model.predict(X_test_bow)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_report = classification_report(y_test, y_pred, target_names=['sadness', 'happiness'])\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842a97e7",
   "metadata": {},
   "source": [
    "## Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "86252518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3e0fbdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on new data\n",
    "x_pred = xgb_model.predict(X_test_bow)\n",
    "y_pred_proba = xgb_model.predict_proba(X_test_bow)\n",
    "\n",
    "#  Calculate precision, recall, and ROC AUC\n",
    "precision = precision_score(y_test, x_pred)\n",
    "recall = recall_score(y_test, x_pred)\n",
    "f1 = f1_score(y_test, x_pred)\n",
    "auc = roc_auc_score(y_test, y_pred_proba[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d6b74eb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.56454545, 0.43545455],\n",
       "       [0.8691249 , 0.1308751 ],\n",
       "       [0.97665673, 0.02334325],\n",
       "       ...,\n",
       "       [0.45226395, 0.54773605],\n",
       "       [0.8400142 , 0.15998581],\n",
       "       [0.035272  , 0.964728  ]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "740ab27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7394366197183099\n",
      "Recall: 0.8275862068965517\n",
      "F1 Score: 0.7810320781032078\n",
      "ROC AUC: 0.8616790593921368\n"
     ]
    }
   ],
   "source": [
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"ROC AUC: {auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f57862",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
